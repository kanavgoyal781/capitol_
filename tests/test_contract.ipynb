{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f937c5ba-ecd7-430d-ba7a-454856f4ffd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "\n",
    "# Import YOUR class and YOUR models\n",
    "# (We try to import QdrantDocument to use it for strict validation)\n",
    "from pipeline import DataTransformer\n",
    "try:\n",
    "    from pipeline import QdrantDocument, MetadataModel\n",
    "except ImportError:\n",
    "    QdrantDocument = None\n",
    "    print(\"âš ï¸ Warning: Could not import QdrantDocument/MetadataModel. Validation will be manual.\")\n",
    "\n",
    "# Load raw data\n",
    "with open(\"data/raw_customer_api.json\", \"r\") as f:\n",
    "    RAW_DATA = json.load(f)\n",
    "\n",
    "# Strict ISO 8601 Regex (YYYY-MM-DDTHH:MM:SSZ)\n",
    "ISO_PATTERN = r\"^\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}(\\.\\d+)?Z$\"\n",
    "\n",
    "@pytest.mark.filterwarnings(\"ignore::bs4.MarkupResemblesLocatorWarning\")\n",
    "def test_pipeline_output_satisfies_contract():\n",
    "    \"\"\"\n",
    "    Contract Test: Validates that every successfully processed document\n",
    "    strictly adheres to the QdrantDocument schema defined in your pipeline.\n",
    "    \"\"\"\n",
    "    transformer = DataTransformer()\n",
    "    print(f\"\\nðŸš€ Starting Contract Test on {len(RAW_DATA)} documents...\")\n",
    "    \n",
    "    results = []\n",
    "    for doc in RAW_DATA:\n",
    "        # Your pipeline returns (result_dict, report_dict)\n",
    "        processed, _ = transformer.process_document(doc)\n",
    "        if processed:\n",
    "            results.append(processed)\n",
    "    \n",
    "    assert len(results) > 0, \"Pipeline returned no documents from valid input\"\n",
    "\n",
    "    for i, doc_dict in enumerate(results, 1):\n",
    "        # --- 1. Schema Validation via Pydantic ---\n",
    "        # If QdrantDocument is available, we use it to strictly validate the dictionary\n",
    "        if QdrantDocument:\n",
    "            try:\n",
    "                validated_doc = QdrantDocument(**doc_dict)\n",
    "                # Convert back to object for easy dot-notation access in assertions below\n",
    "                payload = validated_doc\n",
    "                meta = validated_doc.metadata\n",
    "            except Exception as e:\n",
    "                pytest.fail(f\"Document {i} failed Pydantic validation: {e}\")\n",
    "        else:\n",
    "            # Fallback for manual dict access if import failed\n",
    "            payload = doc_dict # Dictionary\n",
    "            meta = doc_dict.get(\"metadata\", {})\n",
    "        \n",
    "        # --- 2. Logic & Field Name Validation ---\n",
    "        \n",
    "        # Handle difference between Object (dot) and Dict (bracket) access\n",
    "        def get_val(obj, key):\n",
    "            return getattr(obj, key) if not isinstance(obj, dict) else obj.get(key)\n",
    "\n",
    "        doc_id = get_val(meta, \"external_id\")\n",
    "        text = get_val(payload, \"text\")\n",
    "        \n",
    "        # Rule: Text must not be empty\n",
    "        assert len(text.strip()) > 0, f\"Text is empty for {doc_id}\"\n",
    "        \n",
    "        # Rule: Mandatory Fields\n",
    "        assert doc_id, \"External ID cannot be empty\"\n",
    "        url = get_val(meta, \"url\")\n",
    "        assert url and url.startswith(\"http\"), f\"URL must be absolute for {doc_id}\"\n",
    "\n",
    "        # Rule: Lists must be present (not None), even if empty\n",
    "        tags = get_val(meta, \"tags\")\n",
    "        sections = get_val(meta, \"sections\")\n",
    "        categories = get_val(meta, \"categories\")\n",
    "        \n",
    "        assert isinstance(tags, list), f\"Tags must be a list for {doc_id}\"\n",
    "        assert isinstance(sections, list), f\"Sections must be a list for {doc_id}\"\n",
    "        assert isinstance(categories, list), f\"Categories must be a list for {doc_id}\"\n",
    "\n",
    "        # Rule: Dates must be ISO 8601 UTC\n",
    "        p_date = get_val(meta, \"publish_date\")\n",
    "        if p_date:\n",
    "            assert re.match(ISO_PATTERN, p_date), \\\n",
    "                f\"Date {p_date} is not valid ISO 8601 for {doc_id}\"\n",
    "\n",
    "        print(f\"âœ… [{i}/{len(results)}] Schema Validated: {doc_id}\")\n",
    "\n",
    "\n",
    "def test_pipeline_edge_cases_and_resilience():\n",
    "    \"\"\"\n",
    "    Resilience Test: Feeds specific 'broken' inputs to ensure the pipeline\n",
    "    handles them gracefully (skips, defaults, or sanitizes).\n",
    "    \"\"\"\n",
    "    transformer = DataTransformer()\n",
    "\n",
    "    # 1. CASE: Missing Mandatory Field (External ID)\n",
    "    doc_no_id = {\n",
    "        \"type\": \"story\",\n",
    "        \"headlines\": {\"basic\": \"No ID\"},\n",
    "        \"content_elements\": [{\"type\": \"text\", \"content\": \"Text\"}],\n",
    "        \"canonical_website\": \"nj\", # Required for URL logic\n",
    "        \"website_url\": \"/test\"\n",
    "    }\n",
    "    res, report = transformer.process_document(doc_no_id)\n",
    "    assert res is None, \"Pipeline should SKIP document missing '_id'\"\n",
    "    assert report[\"reason\"] == \"Missing ID\"\n",
    "\n",
    "    # 2. CASE: Missing Mandatory Field (Text Content)\n",
    "    doc_no_text = {\n",
    "        \"_id\": \"no_text_01\",\n",
    "        \"canonical_website\": \"nj\", # Required for URL logic\n",
    "        \"website_url\": \"/test\",\n",
    "        \"content_elements\": [] # Empty content\n",
    "    }\n",
    "    res, report = transformer.process_document(doc_no_text)\n",
    "    assert res is None, \"Pipeline should SKIP document with no text\"\n",
    "    assert report[\"reason\"] == \"Missing Text\"\n",
    "\n",
    "    # 3. CASE: Missing Optional Lists (Taxonomy)\n",
    "    # Expected: Process success, but fields default to [] (not None)\n",
    "    doc_no_tax = {\n",
    "        \"_id\": \"defaults_test\",\n",
    "        \"canonical_website\": \"nj\", # Required for URL logic\n",
    "        \"website_url\": \"/test\",\n",
    "        \"content_elements\": [{\"type\": \"text\", \"content\": \"Valid text\"}],\n",
    "        # Completely missing 'taxonomy'\n",
    "    }\n",
    "    res, _ = transformer.process_document(doc_no_tax)\n",
    "    assert res is not None\n",
    "    \n",
    "    # Check that defaults were applied (using Dict access since res is a dict)\n",
    "    meta = res.get(\"metadata\", {})\n",
    "    assert meta.get(\"tags\") == [], \"Missing tags must default to []\"\n",
    "    assert meta.get(\"sections\") == [], \"Missing sections must default to []\"\n",
    "    assert meta.get(\"categories\") == [], \"Missing categories must default to []\"\n",
    "\n",
    "    # 4. CASE: Malformed Date\n",
    "    # Expected: Either skip document OR sanitize date to None\n",
    "    doc_bad_date = {\n",
    "        \"_id\": \"bad_date_01\",\n",
    "        \"canonical_website\": \"nj\", # Required for URL logic\n",
    "        \"website_url\": \"/test\",\n",
    "        \"content_elements\": [{\"type\": \"text\", \"content\": \"Valid text\"}],\n",
    "        \"publish_date\": \"This is garbage\", \n",
    "    }\n",
    "    res, _ = transformer.process_document(doc_bad_date)\n",
    "    \n",
    "    if res:\n",
    "        meta = res.get(\"metadata\", {})\n",
    "        p_date = meta.get(\"publish_date\")\n",
    "        \n",
    "        # If pipeline kept it, the date MUST be valid or None. It cannot be \"garbage\"\n",
    "        if p_date:\n",
    "            assert re.match(ISO_PATTERN, p_date), f\"Pipeline allowed invalid date: {p_date}\"\n",
    "        else:\n",
    "            assert p_date is None\n",
    "\n",
    "    print(\"\\nâœ… Edge Case & Resilience tests passed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
