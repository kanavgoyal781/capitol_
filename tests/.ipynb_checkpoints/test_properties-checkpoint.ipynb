{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5d9fcf-deee-4489-ab38-924495059d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytest\n",
    "# import sys\n",
    "# import os\n",
    "# from hypothesis import given, settings, strategies as st\n",
    "\n",
    "# # Add project root to path\n",
    "# sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "\n",
    "# from pipeline import DataTransformer\n",
    "\n",
    "# # --- 1. DATA GENERATION STRATEGIES ---\n",
    "# # (These generate random structure to fuzz your pipeline)\n",
    "\n",
    "# content_element_strategy = st.fixed_dictionaries({\n",
    "#     \"type\": st.one_of(st.text(), st.none()),\n",
    "#     \"content\": st.one_of(st.text(), st.none()),\n",
    "#     \"additional_properties\": st.one_of(st.dictionaries(st.text(), st.text()), st.none())\n",
    "# })\n",
    "\n",
    "# taxonomy_strategy = st.fixed_dictionaries({\n",
    "#     \"tags\": st.lists(\n",
    "#         st.fixed_dictionaries({\"slug\": st.text(), \"text\": st.text()})\n",
    "#     ),\n",
    "#     \"sections\": st.lists(\n",
    "#         st.fixed_dictionaries({\"name\": st.text(), \"path\": st.text()})\n",
    "#     ),\n",
    "#     \"categories\": st.lists(\n",
    "#         st.fixed_dictionaries({\"name\": st.text(), \"score\": st.floats()})\n",
    "#     )\n",
    "# })\n",
    "\n",
    "# raw_doc_strategy = st.fixed_dictionaries({\n",
    "#     \"_id\": st.one_of(st.text(min_size=1), st.none()),\n",
    "#     \"type\": st.text(),\n",
    "#     \"headlines\": st.one_of(st.none(), st.fixed_dictionaries({\"basic\": st.text()})),\n",
    "#     \"content_elements\": st.lists(content_element_strategy),\n",
    "#     \"taxonomy\": st.one_of(st.none(), taxonomy_strategy),\n",
    "#     \"canonical_url\": st.one_of(st.text(), st.none()),\n",
    "#     \"website_url\": st.one_of(st.text(), st.none()),\n",
    "#     \"canonical_website\": st.one_of(st.text(), st.none()),\n",
    "#     \"publish_date\": st.one_of(st.text(), st.none()),\n",
    "#     \"first_publish_date\": st.one_of(st.text(), st.none()),\n",
    "#     \"display_date\": st.one_of(st.text(), st.none()),\n",
    "#     \"promo_items\": st.one_of(st.none(), st.dictionaries(st.text(), st.text()))\n",
    "# })\n",
    "\n",
    "# # --- 2. THE TEST ---\n",
    "\n",
    "# @settings(max_examples=100)\n",
    "# @given(doc=raw_doc_strategy)\n",
    "# def test_pipeline_resilience_to_garbage_data(doc):\n",
    "#     \"\"\"\n",
    "#     Property Test: Fuzzes the pipeline with valid JSON structure but garbage content.\n",
    "#     Passes if:\n",
    "#     1. The pipeline DOES NOT CRASH (no unhandled exceptions).\n",
    "#     2. Any result returned adheres to the basic flat schema.\n",
    "#     \"\"\"\n",
    "#     transformer = DataTransformer()\n",
    "    \n",
    "#     try:\n",
    "#         result, report = transformer.process_document(doc)\n",
    "        \n",
    "#         # If the pipeline successfully returns a document (didn't skip it),\n",
    "#         # it MUST match your schema's structural rules.\n",
    "#         if result:\n",
    "#             assert isinstance(result, dict), \"Result must be a dictionary\"\n",
    "            \n",
    "#             # Direct Flat Access (No payload wrapper)\n",
    "#             text = result.get(\"text\")\n",
    "#             metadata = result.get(\"metadata\")\n",
    "            \n",
    "#             # Basic Schema Assertions\n",
    "#             assert isinstance(text, str), \"Output 'text' must be a string\"\n",
    "#             assert isinstance(metadata, dict), \"Output 'metadata' must be a dict\"\n",
    "            \n",
    "#             # Check a list field to ensure defaults (like []) are working\n",
    "#             tags = metadata.get(\"tags\")\n",
    "#             assert isinstance(tags, list), \"Metadata 'tags' must be a list (never None)\"\n",
    "            \n",
    "#     except Exception as e:\n",
    "#         # If we catch an exception here, the test fails.\n",
    "#         # This proves the pipeline is not \"crash-proof\" against this specific input.\n",
    "#         pytest.fail(f\"Pipeline CRASHED on valid JSON structure with garbage content.\\nError: {e}\\nInput Doc: {doc}\")\n",
    "\n",
    "import pytest\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "from hypothesis import given, settings, strategies as st\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "\n",
    "from pipeline import DataTransformer\n",
    "\n",
    "# --- 1. DATA GENERATION STRATEGIES ---\n",
    "# (These remain the same, they successfully fuzz the input)\n",
    "\n",
    "content_element_strategy = st.fixed_dictionaries({\n",
    "    \"type\": st.one_of(st.text(), st.none()),\n",
    "    \"content\": st.one_of(st.text(), st.none()),\n",
    "    \"additional_properties\": st.one_of(st.dictionaries(st.text(), st.text()), st.none())\n",
    "})\n",
    "\n",
    "taxonomy_strategy = st.fixed_dictionaries({\n",
    "    \"tags\": st.lists(\n",
    "        st.fixed_dictionaries({\"slug\": st.text(), \"text\": st.text()})\n",
    "    ),\n",
    "    \"sections\": st.lists(\n",
    "        st.fixed_dictionaries({\"name\": st.text(), \"path\": st.text()})\n",
    "    ),\n",
    "    \"categories\": st.lists(\n",
    "        st.fixed_dictionaries({\"name\": st.text(), \"score\": st.floats()})\n",
    "    )\n",
    "})\n",
    "\n",
    "raw_doc_strategy = st.fixed_dictionaries({\n",
    "    # CRITICAL: Allow the _id field to be an empty string, which often causes issues in logging/extraction functions\n",
    "    \"_id\": st.one_of(st.text(min_size=0), st.none()), \n",
    "    \"type\": st.text(),\n",
    "    \"headlines\": st.one_of(st.none(), st.fixed_dictionaries({\"basic\": st.text()})),\n",
    "    \"content_elements\": st.lists(content_element_strategy),\n",
    "    \"taxonomy\": st.one_of(st.none(), taxonomy_strategy),\n",
    "    \"canonical_url\": st.one_of(st.text(), st.none()),\n",
    "    \"website_url\": st.one_of(st.text(), st.none()),\n",
    "    \"canonical_website\": st.one_of(st.text(), st.none()),\n",
    "    \"publish_date\": st.one_of(st.text(), st.none()),\n",
    "    \"first_publish_date\": st.one_of(st.text(), st.none()),\n",
    "    \"display_date\": st.one_of(st.text(), st.none()),\n",
    "    \"promo_items\": st.one_of(st.none(), st.dictionaries(st.text(), st.text()))\n",
    "})\n",
    "\n",
    "# --- 2. THE TEST ---\n",
    "\n",
    "@settings(max_examples=1000)\n",
    "@given(doc=raw_doc_strategy)\n",
    "def test_pipeline_resilience_to_garbage_data(doc):\n",
    "    \"\"\"\n",
    "    Property Test: Fuzzes the pipeline for stability. If a crash occurs, \n",
    "    the test fails and prints the exact input document that caused it.\n",
    "    \"\"\"\n",
    "    transformer = DataTransformer()\n",
    "    \n",
    "    try:\n",
    "        # Use a print statement to capture the input right before the execution\n",
    "        print(f\"--- Attempting Input: {doc['_id'] if doc.get('_id') else 'NO_ID'} ---\")\n",
    "\n",
    "        result, report = transformer.process_document(doc)\n",
    "        \n",
    "        # If the pipeline successfully returns a document (didn't skip it),\n",
    "        if result:\n",
    "            assert isinstance(result, dict), \"Result must be a dictionary\"\n",
    "            \n",
    "            # Direct Flat Access (No payload wrapper)\n",
    "            text = result.get(\"text\")\n",
    "            metadata = result.get(\"metadata\")\n",
    "            \n",
    "            # Basic Schema Assertions\n",
    "            assert isinstance(text, str), \"Output 'text' must be a string\"\n",
    "            assert isinstance(metadata, dict), \"Output 'metadata' must be a dict\"\n",
    "            \n",
    "            # Check a list field to ensure defaults (like []) are working\n",
    "            tags = metadata.get(\"tags\")\n",
    "            assert isinstance(tags, list), \"Metadata 'tags' must be a list (never None)\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        # --- CRASH HANDLER: This forces the crucial debug information to print ---\n",
    "        print(\"\\n\\n######################################################################\")\n",
    "        print(f\"ðŸ›‘ CRASH DETECTED. The minimal failing input was:\")\n",
    "        print(json.dumps(doc, indent=2, ensure_ascii=False))\n",
    "        print(\"######################################################################\\n\")\n",
    "        \n",
    "        # Fail the test with the error\n",
    "        pytest.fail(f\"Pipeline CRASHED on specific input. Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
